temperature                                                                 | Shape: torch.Size([])
image_encoder.model.cls_token                                               | Shape: torch.Size([1, 1, 384])
image_encoder.model.pos_embed                                               | Shape: torch.Size([1, 197, 384])
image_encoder.model.patch_embed.proj.weight                                 | Shape: torch.Size([384, 3, 16, 16])
image_encoder.model.patch_embed.proj.bias                                   | Shape: torch.Size([384])
image_encoder.model.blocks.0.norm1.weight                                   | Shape: torch.Size([384])
image_encoder.model.blocks.0.norm1.bias                                     | Shape: torch.Size([384])
image_encoder.model.blocks.0.attn.qkv.weight                                | Shape: torch.Size([1152, 384])
image_encoder.model.blocks.0.attn.qkv.bias                                  | Shape: torch.Size([1152])
image_encoder.model.blocks.0.attn.proj.weight                               | Shape: torch.Size([384, 384])
image_encoder.model.blocks.0.attn.proj.bias                                 | Shape: torch.Size([384])
image_encoder.model.blocks.0.norm2.weight                                   | Shape: torch.Size([384])
image_encoder.model.blocks.0.norm2.bias                                     | Shape: torch.Size([384])
image_encoder.model.blocks.0.mlp.fc1.weight                                 | Shape: torch.Size([1536, 384])
image_encoder.model.blocks.0.mlp.fc1.bias                                   | Shape: torch.Size([1536])
image_encoder.model.blocks.0.mlp.fc2.weight                                 | Shape: torch.Size([384, 1536])
image_encoder.model.blocks.0.mlp.fc2.bias                                   | Shape: torch.Size([384])
image_encoder.model.blocks.1.norm1.weight                                   | Shape: torch.Size([384])
image_encoder.model.blocks.1.norm1.bias                                     | Shape: torch.Size([384])
image_encoder.model.blocks.1.attn.qkv.weight                                | Shape: torch.Size([1152, 384])
image_encoder.model.blocks.1.attn.qkv.bias                                  | Shape: torch.Size([1152])
image_encoder.model.blocks.1.attn.proj.weight                               | Shape: torch.Size([384, 384])
image_encoder.model.blocks.1.attn.proj.bias                                 | Shape: torch.Size([384])
image_encoder.model.blocks.1.norm2.weight                                   | Shape: torch.Size([384])
image_encoder.model.blocks.1.norm2.bias                                     | Shape: torch.Size([384])
image_encoder.model.blocks.1.mlp.fc1.weight                                 | Shape: torch.Size([1536, 384])
image_encoder.model.blocks.1.mlp.fc1.bias                                   | Shape: torch.Size([1536])
image_encoder.model.blocks.1.mlp.fc2.weight                                 | Shape: torch.Size([384, 1536])
image_encoder.model.blocks.1.mlp.fc2.bias                                   | Shape: torch.Size([384])
image_encoder.model.blocks.2.norm1.weight                                   | Shape: torch.Size([384])
image_encoder.model.blocks.2.norm1.bias                                     | Shape: torch.Size([384])
image_encoder.model.blocks.2.attn.qkv.weight                                | Shape: torch.Size([1152, 384])
image_encoder.model.blocks.2.attn.qkv.bias                                  | Shape: torch.Size([1152])
image_encoder.model.blocks.2.attn.proj.weight                               | Shape: torch.Size([384, 384])
image_encoder.model.blocks.2.attn.proj.bias                                 | Shape: torch.Size([384])
image_encoder.model.blocks.2.norm2.weight                                   | Shape: torch.Size([384])
image_encoder.model.blocks.2.norm2.bias                                     | Shape: torch.Size([384])
image_encoder.model.blocks.2.mlp.fc1.weight                                 | Shape: torch.Size([1536, 384])
image_encoder.model.blocks.2.mlp.fc1.bias                                   | Shape: torch.Size([1536])
image_encoder.model.blocks.2.mlp.fc2.weight                                 | Shape: torch.Size([384, 1536])
image_encoder.model.blocks.2.mlp.fc2.bias                                   | Shape: torch.Size([384])
image_encoder.model.blocks.3.norm1.weight                                   | Shape: torch.Size([384])
image_encoder.model.blocks.3.norm1.bias                                     | Shape: torch.Size([384])
image_encoder.model.blocks.3.attn.qkv.weight                                | Shape: torch.Size([1152, 384])
image_encoder.model.blocks.3.attn.qkv.bias                                  | Shape: torch.Size([1152])
image_encoder.model.blocks.3.attn.proj.weight                               | Shape: torch.Size([384, 384])
image_encoder.model.blocks.3.attn.proj.bias                                 | Shape: torch.Size([384])
image_encoder.model.blocks.3.norm2.weight                                   | Shape: torch.Size([384])
image_encoder.model.blocks.3.norm2.bias                                     | Shape: torch.Size([384])
image_encoder.model.blocks.3.mlp.fc1.weight                                 | Shape: torch.Size([1536, 384])
image_encoder.model.blocks.3.mlp.fc1.bias                                   | Shape: torch.Size([1536])
image_encoder.model.blocks.3.mlp.fc2.weight                                 | Shape: torch.Size([384, 1536])
image_encoder.model.blocks.3.mlp.fc2.bias                                   | Shape: torch.Size([384])
image_encoder.model.blocks.4.norm1.weight                                   | Shape: torch.Size([384])
image_encoder.model.blocks.4.norm1.bias                                     | Shape: torch.Size([384])
image_encoder.model.blocks.4.attn.qkv.weight                                | Shape: torch.Size([1152, 384])
image_encoder.model.blocks.4.attn.qkv.bias                                  | Shape: torch.Size([1152])
image_encoder.model.blocks.4.attn.proj.weight                               | Shape: torch.Size([384, 384])
image_encoder.model.blocks.4.attn.proj.bias                                 | Shape: torch.Size([384])
image_encoder.model.blocks.4.norm2.weight                                   | Shape: torch.Size([384])
image_encoder.model.blocks.4.norm2.bias                                     | Shape: torch.Size([384])
image_encoder.model.blocks.4.mlp.fc1.weight                                 | Shape: torch.Size([1536, 384])
image_encoder.model.blocks.4.mlp.fc1.bias                                   | Shape: torch.Size([1536])
image_encoder.model.blocks.4.mlp.fc2.weight                                 | Shape: torch.Size([384, 1536])
image_encoder.model.blocks.4.mlp.fc2.bias                                   | Shape: torch.Size([384])
image_encoder.model.blocks.5.norm1.weight                                   | Shape: torch.Size([384])
image_encoder.model.blocks.5.norm1.bias                                     | Shape: torch.Size([384])
image_encoder.model.blocks.5.attn.qkv.weight                                | Shape: torch.Size([1152, 384])
image_encoder.model.blocks.5.attn.qkv.bias                                  | Shape: torch.Size([1152])
image_encoder.model.blocks.5.attn.proj.weight                               | Shape: torch.Size([384, 384])
image_encoder.model.blocks.5.attn.proj.bias                                 | Shape: torch.Size([384])
image_encoder.model.blocks.5.norm2.weight                                   | Shape: torch.Size([384])
image_encoder.model.blocks.5.norm2.bias                                     | Shape: torch.Size([384])
image_encoder.model.blocks.5.mlp.fc1.weight                                 | Shape: torch.Size([1536, 384])
image_encoder.model.blocks.5.mlp.fc1.bias                                   | Shape: torch.Size([1536])
image_encoder.model.blocks.5.mlp.fc2.weight                                 | Shape: torch.Size([384, 1536])
image_encoder.model.blocks.5.mlp.fc2.bias                                   | Shape: torch.Size([384])
image_encoder.model.blocks.6.norm1.weight                                   | Shape: torch.Size([384])
image_encoder.model.blocks.6.norm1.bias                                     | Shape: torch.Size([384])
image_encoder.model.blocks.6.attn.qkv.weight                                | Shape: torch.Size([1152, 384])
image_encoder.model.blocks.6.attn.qkv.bias                                  | Shape: torch.Size([1152])
image_encoder.model.blocks.6.attn.proj.weight                               | Shape: torch.Size([384, 384])
image_encoder.model.blocks.6.attn.proj.bias                                 | Shape: torch.Size([384])
image_encoder.model.blocks.6.norm2.weight                                   | Shape: torch.Size([384])
image_encoder.model.blocks.6.norm2.bias                                     | Shape: torch.Size([384])
image_encoder.model.blocks.6.mlp.fc1.weight                                 | Shape: torch.Size([1536, 384])
image_encoder.model.blocks.6.mlp.fc1.bias                                   | Shape: torch.Size([1536])
image_encoder.model.blocks.6.mlp.fc2.weight                                 | Shape: torch.Size([384, 1536])
image_encoder.model.blocks.6.mlp.fc2.bias                                   | Shape: torch.Size([384])
image_encoder.model.blocks.7.norm1.weight                                   | Shape: torch.Size([384])
image_encoder.model.blocks.7.norm1.bias                                     | Shape: torch.Size([384])
image_encoder.model.blocks.7.attn.qkv.weight                                | Shape: torch.Size([1152, 384])
image_encoder.model.blocks.7.attn.qkv.bias                                  | Shape: torch.Size([1152])
image_encoder.model.blocks.7.attn.proj.weight                               | Shape: torch.Size([384, 384])
image_encoder.model.blocks.7.attn.proj.bias                                 | Shape: torch.Size([384])
image_encoder.model.blocks.7.norm2.weight                                   | Shape: torch.Size([384])
image_encoder.model.blocks.7.norm2.bias                                     | Shape: torch.Size([384])
image_encoder.model.blocks.7.mlp.fc1.weight                                 | Shape: torch.Size([1536, 384])
image_encoder.model.blocks.7.mlp.fc1.bias                                   | Shape: torch.Size([1536])
image_encoder.model.blocks.7.mlp.fc2.weight                                 | Shape: torch.Size([384, 1536])
image_encoder.model.blocks.7.mlp.fc2.bias                                   | Shape: torch.Size([384])
image_encoder.model.blocks.8.norm1.weight                                   | Shape: torch.Size([384])
image_encoder.model.blocks.8.norm1.bias                                     | Shape: torch.Size([384])
image_encoder.model.blocks.8.attn.qkv.weight                                | Shape: torch.Size([1152, 384])
image_encoder.model.blocks.8.attn.qkv.bias                                  | Shape: torch.Size([1152])
image_encoder.model.blocks.8.attn.proj.weight                               | Shape: torch.Size([384, 384])
image_encoder.model.blocks.8.attn.proj.bias                                 | Shape: torch.Size([384])
image_encoder.model.blocks.8.norm2.weight                                   | Shape: torch.Size([384])
image_encoder.model.blocks.8.norm2.bias                                     | Shape: torch.Size([384])
image_encoder.model.blocks.8.mlp.fc1.weight                                 | Shape: torch.Size([1536, 384])
image_encoder.model.blocks.8.mlp.fc1.bias                                   | Shape: torch.Size([1536])
image_encoder.model.blocks.8.mlp.fc2.weight                                 | Shape: torch.Size([384, 1536])
image_encoder.model.blocks.8.mlp.fc2.bias                                   | Shape: torch.Size([384])
image_encoder.model.blocks.9.norm1.weight                                   | Shape: torch.Size([384])
image_encoder.model.blocks.9.norm1.bias                                     | Shape: torch.Size([384])
image_encoder.model.blocks.9.attn.qkv.weight                                | Shape: torch.Size([1152, 384])
image_encoder.model.blocks.9.attn.qkv.bias                                  | Shape: torch.Size([1152])
image_encoder.model.blocks.9.attn.proj.weight                               | Shape: torch.Size([384, 384])
image_encoder.model.blocks.9.attn.proj.bias                                 | Shape: torch.Size([384])
image_encoder.model.blocks.9.norm2.weight                                   | Shape: torch.Size([384])
image_encoder.model.blocks.9.norm2.bias                                     | Shape: torch.Size([384])
image_encoder.model.blocks.9.mlp.fc1.weight                                 | Shape: torch.Size([1536, 384])
image_encoder.model.blocks.9.mlp.fc1.bias                                   | Shape: torch.Size([1536])
image_encoder.model.blocks.9.mlp.fc2.weight                                 | Shape: torch.Size([384, 1536])
image_encoder.model.blocks.9.mlp.fc2.bias                                   | Shape: torch.Size([384])
image_encoder.model.blocks.10.norm1.weight                                  | Shape: torch.Size([384])
image_encoder.model.blocks.10.norm1.bias                                    | Shape: torch.Size([384])
image_encoder.model.blocks.10.attn.qkv.weight                               | Shape: torch.Size([1152, 384])
image_encoder.model.blocks.10.attn.qkv.bias                                 | Shape: torch.Size([1152])
image_encoder.model.blocks.10.attn.proj.weight                              | Shape: torch.Size([384, 384])
image_encoder.model.blocks.10.attn.proj.bias                                | Shape: torch.Size([384])
image_encoder.model.blocks.10.norm2.weight                                  | Shape: torch.Size([384])
image_encoder.model.blocks.10.norm2.bias                                    | Shape: torch.Size([384])
image_encoder.model.blocks.10.mlp.fc1.weight                                | Shape: torch.Size([1536, 384])
image_encoder.model.blocks.10.mlp.fc1.bias                                  | Shape: torch.Size([1536])
image_encoder.model.blocks.10.mlp.fc2.weight                                | Shape: torch.Size([384, 1536])
image_encoder.model.blocks.10.mlp.fc2.bias                                  | Shape: torch.Size([384])
image_encoder.model.blocks.11.norm1.weight                                  | Shape: torch.Size([384])
image_encoder.model.blocks.11.norm1.bias                                    | Shape: torch.Size([384])
image_encoder.model.blocks.11.attn.qkv.weight                               | Shape: torch.Size([1152, 384])
image_encoder.model.blocks.11.attn.qkv.bias                                 | Shape: torch.Size([1152])
image_encoder.model.blocks.11.attn.proj.weight                              | Shape: torch.Size([384, 384])
image_encoder.model.blocks.11.attn.proj.bias                                | Shape: torch.Size([384])
image_encoder.model.blocks.11.norm2.weight                                  | Shape: torch.Size([384])
image_encoder.model.blocks.11.norm2.bias                                    | Shape: torch.Size([384])
image_encoder.model.blocks.11.mlp.fc1.weight                                | Shape: torch.Size([1536, 384])
image_encoder.model.blocks.11.mlp.fc1.bias                                  | Shape: torch.Size([1536])
image_encoder.model.blocks.11.mlp.fc2.weight                                | Shape: torch.Size([384, 1536])
image_encoder.model.blocks.11.mlp.fc2.bias                                  | Shape: torch.Size([384])
image_encoder.model.norm.weight                                             | Shape: torch.Size([384])
image_encoder.model.norm.bias                                               | Shape: torch.Size([384])
image_encoder.projection.weight                                             | Shape: torch.Size([384, 384])
image_encoder.projection.bias                                               | Shape: torch.Size([384])
lidar_encoder.model.backbone.conv_input.0.net.0.kernel                      | Shape: torch.Size([27, 4, 32])
lidar_encoder.model.backbone.conv_input.0.net.1.weight                      | Shape: torch.Size([32])
lidar_encoder.model.backbone.conv_input.0.net.1.bias                        | Shape: torch.Size([32])
lidar_encoder.model.backbone.conv_input.0.net.1.running_mean                | Shape: torch.Size([32])
lidar_encoder.model.backbone.conv_input.0.net.1.running_var                 | Shape: torch.Size([32])
lidar_encoder.model.backbone.conv_input.0.net.1.num_batches_tracked         | Shape: torch.Size([])
lidar_encoder.model.backbone.conv_input.1.net.0.kernel                      | Shape: torch.Size([27, 32, 32])
lidar_encoder.model.backbone.conv_input.1.net.1.weight                      | Shape: torch.Size([32])
lidar_encoder.model.backbone.conv_input.1.net.1.bias                        | Shape: torch.Size([32])
lidar_encoder.model.backbone.conv_input.1.net.1.running_mean                | Shape: torch.Size([32])
lidar_encoder.model.backbone.conv_input.1.net.1.running_var                 | Shape: torch.Size([32])
lidar_encoder.model.backbone.conv_input.1.net.1.num_batches_tracked         | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.0.0.net.0.kernel                       | Shape: torch.Size([8, 32, 32])
lidar_encoder.model.backbone.encoder.0.0.net.1.weight                       | Shape: torch.Size([32])
lidar_encoder.model.backbone.encoder.0.0.net.1.bias                         | Shape: torch.Size([32])
lidar_encoder.model.backbone.encoder.0.0.net.1.running_mean                 | Shape: torch.Size([32])
lidar_encoder.model.backbone.encoder.0.0.net.1.running_var                  | Shape: torch.Size([32])
lidar_encoder.model.backbone.encoder.0.0.net.1.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.0.1.net.0.kernel                       | Shape: torch.Size([27, 32, 32])
lidar_encoder.model.backbone.encoder.0.1.net.1.weight                       | Shape: torch.Size([32])
lidar_encoder.model.backbone.encoder.0.1.net.1.bias                         | Shape: torch.Size([32])
lidar_encoder.model.backbone.encoder.0.1.net.1.running_mean                 | Shape: torch.Size([32])
lidar_encoder.model.backbone.encoder.0.1.net.1.running_var                  | Shape: torch.Size([32])
lidar_encoder.model.backbone.encoder.0.1.net.1.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.0.1.net.3.kernel                       | Shape: torch.Size([27, 32, 32])
lidar_encoder.model.backbone.encoder.0.1.net.4.weight                       | Shape: torch.Size([32])
lidar_encoder.model.backbone.encoder.0.1.net.4.bias                         | Shape: torch.Size([32])
lidar_encoder.model.backbone.encoder.0.1.net.4.running_mean                 | Shape: torch.Size([32])
lidar_encoder.model.backbone.encoder.0.1.net.4.running_var                  | Shape: torch.Size([32])
lidar_encoder.model.backbone.encoder.0.1.net.4.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.0.2.net.0.kernel                       | Shape: torch.Size([27, 32, 32])
lidar_encoder.model.backbone.encoder.0.2.net.1.weight                       | Shape: torch.Size([32])
lidar_encoder.model.backbone.encoder.0.2.net.1.bias                         | Shape: torch.Size([32])
lidar_encoder.model.backbone.encoder.0.2.net.1.running_mean                 | Shape: torch.Size([32])
lidar_encoder.model.backbone.encoder.0.2.net.1.running_var                  | Shape: torch.Size([32])
lidar_encoder.model.backbone.encoder.0.2.net.1.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.0.2.net.3.kernel                       | Shape: torch.Size([27, 32, 32])
lidar_encoder.model.backbone.encoder.0.2.net.4.weight                       | Shape: torch.Size([32])
lidar_encoder.model.backbone.encoder.0.2.net.4.bias                         | Shape: torch.Size([32])
lidar_encoder.model.backbone.encoder.0.2.net.4.running_mean                 | Shape: torch.Size([32])
lidar_encoder.model.backbone.encoder.0.2.net.4.running_var                  | Shape: torch.Size([32])
lidar_encoder.model.backbone.encoder.0.2.net.4.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.1.0.net.0.kernel                       | Shape: torch.Size([8, 32, 32])
lidar_encoder.model.backbone.encoder.1.0.net.1.weight                       | Shape: torch.Size([32])
lidar_encoder.model.backbone.encoder.1.0.net.1.bias                         | Shape: torch.Size([32])
lidar_encoder.model.backbone.encoder.1.0.net.1.running_mean                 | Shape: torch.Size([32])
lidar_encoder.model.backbone.encoder.1.0.net.1.running_var                  | Shape: torch.Size([32])
lidar_encoder.model.backbone.encoder.1.0.net.1.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.1.1.net.0.kernel                       | Shape: torch.Size([27, 32, 64])
lidar_encoder.model.backbone.encoder.1.1.net.1.weight                       | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.1.net.1.bias                         | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.1.net.1.running_mean                 | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.1.net.1.running_var                  | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.1.net.1.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.1.1.net.3.kernel                       | Shape: torch.Size([27, 64, 64])
lidar_encoder.model.backbone.encoder.1.1.net.4.weight                       | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.1.net.4.bias                         | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.1.net.4.running_mean                 | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.1.net.4.running_var                  | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.1.net.4.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.1.1.downsample.0.kernel                | Shape: torch.Size([32, 64])
lidar_encoder.model.backbone.encoder.1.1.downsample.1.weight                | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.1.downsample.1.bias                  | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.1.downsample.1.running_mean          | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.1.downsample.1.running_var           | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.1.downsample.1.num_batches_tracked   | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.1.2.net.0.kernel                       | Shape: torch.Size([27, 64, 64])
lidar_encoder.model.backbone.encoder.1.2.net.1.weight                       | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.2.net.1.bias                         | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.2.net.1.running_mean                 | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.2.net.1.running_var                  | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.2.net.1.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.1.2.net.3.kernel                       | Shape: torch.Size([27, 64, 64])
lidar_encoder.model.backbone.encoder.1.2.net.4.weight                       | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.2.net.4.bias                         | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.2.net.4.running_mean                 | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.2.net.4.running_var                  | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.2.net.4.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.1.3.net.0.kernel                       | Shape: torch.Size([27, 64, 64])
lidar_encoder.model.backbone.encoder.1.3.net.1.weight                       | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.3.net.1.bias                         | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.3.net.1.running_mean                 | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.3.net.1.running_var                  | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.3.net.1.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.1.3.net.3.kernel                       | Shape: torch.Size([27, 64, 64])
lidar_encoder.model.backbone.encoder.1.3.net.4.weight                       | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.3.net.4.bias                         | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.3.net.4.running_mean                 | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.3.net.4.running_var                  | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.1.3.net.4.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.2.0.net.0.kernel                       | Shape: torch.Size([8, 64, 64])
lidar_encoder.model.backbone.encoder.2.0.net.1.weight                       | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.2.0.net.1.bias                         | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.2.0.net.1.running_mean                 | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.2.0.net.1.running_var                  | Shape: torch.Size([64])
lidar_encoder.model.backbone.encoder.2.0.net.1.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.2.1.net.0.kernel                       | Shape: torch.Size([27, 64, 128])
lidar_encoder.model.backbone.encoder.2.1.net.1.weight                       | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.1.net.1.bias                         | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.1.net.1.running_mean                 | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.1.net.1.running_var                  | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.1.net.1.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.2.1.net.3.kernel                       | Shape: torch.Size([27, 128, 128])
lidar_encoder.model.backbone.encoder.2.1.net.4.weight                       | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.1.net.4.bias                         | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.1.net.4.running_mean                 | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.1.net.4.running_var                  | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.1.net.4.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.2.1.downsample.0.kernel                | Shape: torch.Size([64, 128])
lidar_encoder.model.backbone.encoder.2.1.downsample.1.weight                | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.1.downsample.1.bias                  | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.1.downsample.1.running_mean          | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.1.downsample.1.running_var           | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.1.downsample.1.num_batches_tracked   | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.2.2.net.0.kernel                       | Shape: torch.Size([27, 128, 128])
lidar_encoder.model.backbone.encoder.2.2.net.1.weight                       | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.2.net.1.bias                         | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.2.net.1.running_mean                 | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.2.net.1.running_var                  | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.2.net.1.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.2.2.net.3.kernel                       | Shape: torch.Size([27, 128, 128])
lidar_encoder.model.backbone.encoder.2.2.net.4.weight                       | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.2.net.4.bias                         | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.2.net.4.running_mean                 | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.2.net.4.running_var                  | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.2.net.4.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.2.3.net.0.kernel                       | Shape: torch.Size([27, 128, 128])
lidar_encoder.model.backbone.encoder.2.3.net.1.weight                       | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.3.net.1.bias                         | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.3.net.1.running_mean                 | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.3.net.1.running_var                  | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.3.net.1.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.2.3.net.3.kernel                       | Shape: torch.Size([27, 128, 128])
lidar_encoder.model.backbone.encoder.2.3.net.4.weight                       | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.3.net.4.bias                         | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.3.net.4.running_mean                 | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.3.net.4.running_var                  | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.3.net.4.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.2.4.net.0.kernel                       | Shape: torch.Size([27, 128, 128])
lidar_encoder.model.backbone.encoder.2.4.net.1.weight                       | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.4.net.1.bias                         | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.4.net.1.running_mean                 | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.4.net.1.running_var                  | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.4.net.1.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.2.4.net.3.kernel                       | Shape: torch.Size([27, 128, 128])
lidar_encoder.model.backbone.encoder.2.4.net.4.weight                       | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.4.net.4.bias                         | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.4.net.4.running_mean                 | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.4.net.4.running_var                  | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.2.4.net.4.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.3.0.net.0.kernel                       | Shape: torch.Size([8, 128, 128])
lidar_encoder.model.backbone.encoder.3.0.net.1.weight                       | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.3.0.net.1.bias                         | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.3.0.net.1.running_mean                 | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.3.0.net.1.running_var                  | Shape: torch.Size([128])
lidar_encoder.model.backbone.encoder.3.0.net.1.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.3.1.net.0.kernel                       | Shape: torch.Size([27, 128, 256])
lidar_encoder.model.backbone.encoder.3.1.net.1.weight                       | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.1.net.1.bias                         | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.1.net.1.running_mean                 | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.1.net.1.running_var                  | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.1.net.1.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.3.1.net.3.kernel                       | Shape: torch.Size([27, 256, 256])
lidar_encoder.model.backbone.encoder.3.1.net.4.weight                       | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.1.net.4.bias                         | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.1.net.4.running_mean                 | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.1.net.4.running_var                  | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.1.net.4.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.3.1.downsample.0.kernel                | Shape: torch.Size([128, 256])
lidar_encoder.model.backbone.encoder.3.1.downsample.1.weight                | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.1.downsample.1.bias                  | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.1.downsample.1.running_mean          | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.1.downsample.1.running_var           | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.1.downsample.1.num_batches_tracked   | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.3.2.net.0.kernel                       | Shape: torch.Size([27, 256, 256])
lidar_encoder.model.backbone.encoder.3.2.net.1.weight                       | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.2.net.1.bias                         | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.2.net.1.running_mean                 | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.2.net.1.running_var                  | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.2.net.1.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.3.2.net.3.kernel                       | Shape: torch.Size([27, 256, 256])
lidar_encoder.model.backbone.encoder.3.2.net.4.weight                       | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.2.net.4.bias                         | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.2.net.4.running_mean                 | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.2.net.4.running_var                  | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.2.net.4.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.3.3.net.0.kernel                       | Shape: torch.Size([27, 256, 256])
lidar_encoder.model.backbone.encoder.3.3.net.1.weight                       | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.3.net.1.bias                         | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.3.net.1.running_mean                 | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.3.net.1.running_var                  | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.3.net.1.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.3.3.net.3.kernel                       | Shape: torch.Size([27, 256, 256])
lidar_encoder.model.backbone.encoder.3.3.net.4.weight                       | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.3.net.4.bias                         | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.3.net.4.running_mean                 | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.3.net.4.running_var                  | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.3.net.4.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.3.4.net.0.kernel                       | Shape: torch.Size([27, 256, 256])
lidar_encoder.model.backbone.encoder.3.4.net.1.weight                       | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.4.net.1.bias                         | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.4.net.1.running_mean                 | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.4.net.1.running_var                  | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.4.net.1.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.3.4.net.3.kernel                       | Shape: torch.Size([27, 256, 256])
lidar_encoder.model.backbone.encoder.3.4.net.4.weight                       | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.4.net.4.bias                         | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.4.net.4.running_mean                 | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.4.net.4.running_var                  | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.4.net.4.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.3.5.net.0.kernel                       | Shape: torch.Size([27, 256, 256])
lidar_encoder.model.backbone.encoder.3.5.net.1.weight                       | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.5.net.1.bias                         | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.5.net.1.running_mean                 | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.5.net.1.running_var                  | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.5.net.1.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.3.5.net.3.kernel                       | Shape: torch.Size([27, 256, 256])
lidar_encoder.model.backbone.encoder.3.5.net.4.weight                       | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.5.net.4.bias                         | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.5.net.4.running_mean                 | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.5.net.4.running_var                  | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.5.net.4.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.3.6.net.0.kernel                       | Shape: torch.Size([27, 256, 256])
lidar_encoder.model.backbone.encoder.3.6.net.1.weight                       | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.6.net.1.bias                         | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.6.net.1.running_mean                 | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.6.net.1.running_var                  | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.6.net.1.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.encoder.3.6.net.3.kernel                       | Shape: torch.Size([27, 256, 256])
lidar_encoder.model.backbone.encoder.3.6.net.4.weight                       | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.6.net.4.bias                         | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.6.net.4.running_mean                 | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.6.net.4.running_var                  | Shape: torch.Size([256])
lidar_encoder.model.backbone.encoder.3.6.net.4.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.decoder.0.0.net.0.kernel                       | Shape: torch.Size([8, 256, 256])
lidar_encoder.model.backbone.decoder.0.0.net.1.weight                       | Shape: torch.Size([256])
lidar_encoder.model.backbone.decoder.0.0.net.1.bias                         | Shape: torch.Size([256])
lidar_encoder.model.backbone.decoder.0.0.net.1.running_mean                 | Shape: torch.Size([256])
lidar_encoder.model.backbone.decoder.0.0.net.1.running_var                  | Shape: torch.Size([256])
lidar_encoder.model.backbone.decoder.0.0.net.1.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.decoder.0.1.0.net.0.kernel                     | Shape: torch.Size([27, 384, 256])
lidar_encoder.model.backbone.decoder.0.1.0.net.1.weight                     | Shape: torch.Size([256])
lidar_encoder.model.backbone.decoder.0.1.0.net.1.bias                       | Shape: torch.Size([256])
lidar_encoder.model.backbone.decoder.0.1.0.net.1.running_mean               | Shape: torch.Size([256])
lidar_encoder.model.backbone.decoder.0.1.0.net.1.running_var                | Shape: torch.Size([256])
lidar_encoder.model.backbone.decoder.0.1.0.net.1.num_batches_tracked        | Shape: torch.Size([])
lidar_encoder.model.backbone.decoder.0.1.0.net.3.kernel                     | Shape: torch.Size([27, 256, 256])
lidar_encoder.model.backbone.decoder.0.1.0.net.4.weight                     | Shape: torch.Size([256])
lidar_encoder.model.backbone.decoder.0.1.0.net.4.bias                       | Shape: torch.Size([256])
lidar_encoder.model.backbone.decoder.0.1.0.net.4.running_mean               | Shape: torch.Size([256])
lidar_encoder.model.backbone.decoder.0.1.0.net.4.running_var                | Shape: torch.Size([256])
lidar_encoder.model.backbone.decoder.0.1.0.net.4.num_batches_tracked        | Shape: torch.Size([])
lidar_encoder.model.backbone.decoder.0.1.0.downsample.0.kernel              | Shape: torch.Size([384, 256])
lidar_encoder.model.backbone.decoder.0.1.0.downsample.1.weight              | Shape: torch.Size([256])
lidar_encoder.model.backbone.decoder.0.1.0.downsample.1.bias                | Shape: torch.Size([256])
lidar_encoder.model.backbone.decoder.0.1.0.downsample.1.running_mean        | Shape: torch.Size([256])
lidar_encoder.model.backbone.decoder.0.1.0.downsample.1.running_var         | Shape: torch.Size([256])
lidar_encoder.model.backbone.decoder.0.1.0.downsample.1.num_batches_tracked | Shape: torch.Size([])
lidar_encoder.model.backbone.decoder.0.1.1.net.0.kernel                     | Shape: torch.Size([27, 256, 256])
lidar_encoder.model.backbone.decoder.0.1.1.net.1.weight                     | Shape: torch.Size([256])
lidar_encoder.model.backbone.decoder.0.1.1.net.1.bias                       | Shape: torch.Size([256])
lidar_encoder.model.backbone.decoder.0.1.1.net.1.running_mean               | Shape: torch.Size([256])
lidar_encoder.model.backbone.decoder.0.1.1.net.1.running_var                | Shape: torch.Size([256])
lidar_encoder.model.backbone.decoder.0.1.1.net.1.num_batches_tracked        | Shape: torch.Size([])
lidar_encoder.model.backbone.decoder.0.1.1.net.3.kernel                     | Shape: torch.Size([27, 256, 256])
lidar_encoder.model.backbone.decoder.0.1.1.net.4.weight                     | Shape: torch.Size([256])
lidar_encoder.model.backbone.decoder.0.1.1.net.4.bias                       | Shape: torch.Size([256])
lidar_encoder.model.backbone.decoder.0.1.1.net.4.running_mean               | Shape: torch.Size([256])
lidar_encoder.model.backbone.decoder.0.1.1.net.4.running_var                | Shape: torch.Size([256])
lidar_encoder.model.backbone.decoder.0.1.1.net.4.num_batches_tracked        | Shape: torch.Size([])
lidar_encoder.model.backbone.decoder.1.0.net.0.kernel                       | Shape: torch.Size([8, 256, 128])
lidar_encoder.model.backbone.decoder.1.0.net.1.weight                       | Shape: torch.Size([128])
lidar_encoder.model.backbone.decoder.1.0.net.1.bias                         | Shape: torch.Size([128])
lidar_encoder.model.backbone.decoder.1.0.net.1.running_mean                 | Shape: torch.Size([128])
lidar_encoder.model.backbone.decoder.1.0.net.1.running_var                  | Shape: torch.Size([128])
lidar_encoder.model.backbone.decoder.1.0.net.1.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.decoder.1.1.0.net.0.kernel                     | Shape: torch.Size([27, 192, 128])
lidar_encoder.model.backbone.decoder.1.1.0.net.1.weight                     | Shape: torch.Size([128])
lidar_encoder.model.backbone.decoder.1.1.0.net.1.bias                       | Shape: torch.Size([128])
lidar_encoder.model.backbone.decoder.1.1.0.net.1.running_mean               | Shape: torch.Size([128])
lidar_encoder.model.backbone.decoder.1.1.0.net.1.running_var                | Shape: torch.Size([128])
lidar_encoder.model.backbone.decoder.1.1.0.net.1.num_batches_tracked        | Shape: torch.Size([])
lidar_encoder.model.backbone.decoder.1.1.0.net.3.kernel                     | Shape: torch.Size([27, 128, 128])
lidar_encoder.model.backbone.decoder.1.1.0.net.4.weight                     | Shape: torch.Size([128])
lidar_encoder.model.backbone.decoder.1.1.0.net.4.bias                       | Shape: torch.Size([128])
lidar_encoder.model.backbone.decoder.1.1.0.net.4.running_mean               | Shape: torch.Size([128])
lidar_encoder.model.backbone.decoder.1.1.0.net.4.running_var                | Shape: torch.Size([128])
lidar_encoder.model.backbone.decoder.1.1.0.net.4.num_batches_tracked        | Shape: torch.Size([])
lidar_encoder.model.backbone.decoder.1.1.0.downsample.0.kernel              | Shape: torch.Size([192, 128])
lidar_encoder.model.backbone.decoder.1.1.0.downsample.1.weight              | Shape: torch.Size([128])
lidar_encoder.model.backbone.decoder.1.1.0.downsample.1.bias                | Shape: torch.Size([128])
lidar_encoder.model.backbone.decoder.1.1.0.downsample.1.running_mean        | Shape: torch.Size([128])
lidar_encoder.model.backbone.decoder.1.1.0.downsample.1.running_var         | Shape: torch.Size([128])
lidar_encoder.model.backbone.decoder.1.1.0.downsample.1.num_batches_tracked | Shape: torch.Size([])
lidar_encoder.model.backbone.decoder.1.1.1.net.0.kernel                     | Shape: torch.Size([27, 128, 128])
lidar_encoder.model.backbone.decoder.1.1.1.net.1.weight                     | Shape: torch.Size([128])
lidar_encoder.model.backbone.decoder.1.1.1.net.1.bias                       | Shape: torch.Size([128])
lidar_encoder.model.backbone.decoder.1.1.1.net.1.running_mean               | Shape: torch.Size([128])
lidar_encoder.model.backbone.decoder.1.1.1.net.1.running_var                | Shape: torch.Size([128])
lidar_encoder.model.backbone.decoder.1.1.1.net.1.num_batches_tracked        | Shape: torch.Size([])
lidar_encoder.model.backbone.decoder.1.1.1.net.3.kernel                     | Shape: torch.Size([27, 128, 128])
lidar_encoder.model.backbone.decoder.1.1.1.net.4.weight                     | Shape: torch.Size([128])
lidar_encoder.model.backbone.decoder.1.1.1.net.4.bias                       | Shape: torch.Size([128])
lidar_encoder.model.backbone.decoder.1.1.1.net.4.running_mean               | Shape: torch.Size([128])
lidar_encoder.model.backbone.decoder.1.1.1.net.4.running_var                | Shape: torch.Size([128])
lidar_encoder.model.backbone.decoder.1.1.1.net.4.num_batches_tracked        | Shape: torch.Size([])
lidar_encoder.model.backbone.decoder.2.0.net.0.kernel                       | Shape: torch.Size([8, 128, 96])
lidar_encoder.model.backbone.decoder.2.0.net.1.weight                       | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.2.0.net.1.bias                         | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.2.0.net.1.running_mean                 | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.2.0.net.1.running_var                  | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.2.0.net.1.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.decoder.2.1.0.net.0.kernel                     | Shape: torch.Size([27, 128, 96])
lidar_encoder.model.backbone.decoder.2.1.0.net.1.weight                     | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.2.1.0.net.1.bias                       | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.2.1.0.net.1.running_mean               | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.2.1.0.net.1.running_var                | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.2.1.0.net.1.num_batches_tracked        | Shape: torch.Size([])
lidar_encoder.model.backbone.decoder.2.1.0.net.3.kernel                     | Shape: torch.Size([27, 96, 96])
lidar_encoder.model.backbone.decoder.2.1.0.net.4.weight                     | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.2.1.0.net.4.bias                       | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.2.1.0.net.4.running_mean               | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.2.1.0.net.4.running_var                | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.2.1.0.net.4.num_batches_tracked        | Shape: torch.Size([])
lidar_encoder.model.backbone.decoder.2.1.0.downsample.0.kernel              | Shape: torch.Size([128, 96])
lidar_encoder.model.backbone.decoder.2.1.0.downsample.1.weight              | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.2.1.0.downsample.1.bias                | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.2.1.0.downsample.1.running_mean        | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.2.1.0.downsample.1.running_var         | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.2.1.0.downsample.1.num_batches_tracked | Shape: torch.Size([])
lidar_encoder.model.backbone.decoder.2.1.1.net.0.kernel                     | Shape: torch.Size([27, 96, 96])
lidar_encoder.model.backbone.decoder.2.1.1.net.1.weight                     | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.2.1.1.net.1.bias                       | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.2.1.1.net.1.running_mean               | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.2.1.1.net.1.running_var                | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.2.1.1.net.1.num_batches_tracked        | Shape: torch.Size([])
lidar_encoder.model.backbone.decoder.2.1.1.net.3.kernel                     | Shape: torch.Size([27, 96, 96])
lidar_encoder.model.backbone.decoder.2.1.1.net.4.weight                     | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.2.1.1.net.4.bias                       | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.2.1.1.net.4.running_mean               | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.2.1.1.net.4.running_var                | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.2.1.1.net.4.num_batches_tracked        | Shape: torch.Size([])
lidar_encoder.model.backbone.decoder.3.0.net.0.kernel                       | Shape: torch.Size([8, 96, 96])
lidar_encoder.model.backbone.decoder.3.0.net.1.weight                       | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.3.0.net.1.bias                         | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.3.0.net.1.running_mean                 | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.3.0.net.1.running_var                  | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.3.0.net.1.num_batches_tracked          | Shape: torch.Size([])
lidar_encoder.model.backbone.decoder.3.1.0.net.0.kernel                     | Shape: torch.Size([27, 128, 96])
lidar_encoder.model.backbone.decoder.3.1.0.net.1.weight                     | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.3.1.0.net.1.bias                       | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.3.1.0.net.1.running_mean               | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.3.1.0.net.1.running_var                | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.3.1.0.net.1.num_batches_tracked        | Shape: torch.Size([])
lidar_encoder.model.backbone.decoder.3.1.0.net.3.kernel                     | Shape: torch.Size([27, 96, 96])
lidar_encoder.model.backbone.decoder.3.1.0.net.4.weight                     | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.3.1.0.net.4.bias                       | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.3.1.0.net.4.running_mean               | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.3.1.0.net.4.running_var                | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.3.1.0.net.4.num_batches_tracked        | Shape: torch.Size([])
lidar_encoder.model.backbone.decoder.3.1.0.downsample.0.kernel              | Shape: torch.Size([128, 96])
lidar_encoder.model.backbone.decoder.3.1.0.downsample.1.weight              | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.3.1.0.downsample.1.bias                | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.3.1.0.downsample.1.running_mean        | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.3.1.0.downsample.1.running_var         | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.3.1.0.downsample.1.num_batches_tracked | Shape: torch.Size([])
lidar_encoder.model.backbone.decoder.3.1.1.net.0.kernel                     | Shape: torch.Size([27, 96, 96])
lidar_encoder.model.backbone.decoder.3.1.1.net.1.weight                     | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.3.1.1.net.1.bias                       | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.3.1.1.net.1.running_mean               | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.3.1.1.net.1.running_var                | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.3.1.1.net.1.num_batches_tracked        | Shape: torch.Size([])
lidar_encoder.model.backbone.decoder.3.1.1.net.3.kernel                     | Shape: torch.Size([27, 96, 96])
lidar_encoder.model.backbone.decoder.3.1.1.net.4.weight                     | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.3.1.1.net.4.bias                       | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.3.1.1.net.4.running_mean               | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.3.1.1.net.4.running_var                | Shape: torch.Size([96])
lidar_encoder.model.backbone.decoder.3.1.1.net.4.num_batches_tracked        | Shape: torch.Size([])
lidar_encoder.model.decode_head.conv_seg.weight                             | Shape: torch.Size([19, 96])
lidar_encoder.model.decode_head.conv_seg.bias                               | Shape: torch.Size([19])
lidar_encoder.projection.weight                                             | Shape: torch.Size([384, 96])
lidar_encoder.projection.bias                                               | Shape: torch.Size([384])
